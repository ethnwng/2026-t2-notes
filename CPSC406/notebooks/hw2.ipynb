{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea3c52c-b1e0-4e17-871b-9726dae8a627",
   "metadata": {},
   "source": [
    "# Gradients, Jacobians, and Positive Definiteness\n",
    "\n",
    "$$\n",
    "\\def\\argmin{\\operatorname*{argmin}}\n",
    "\\def\\argmax{\\operatorname*{argmax}}\n",
    "\\def\\Ball{\\mathbf{B}}\n",
    "\\def\\bmat#1{\\begin{bmatrix}#1\\end{bmatrix}}\n",
    "\\def\\Diag{\\mathbf{Diag}}\n",
    "\\def\\half{\\tfrac{1}{2}}\n",
    "\\def\\int{\\mathop{\\rm int}}\n",
    "\\def\\ip#1{\\langle #1 \\rangle}\n",
    "\\def\\maxim{\\mathop{\\hbox{\\rm maximize}}}\n",
    "\\def\\maximize#1{\\displaystyle\\maxim_{#1}}\n",
    "\\def\\minim{\\mathop{\\hbox{\\rm minimize}}}\n",
    "\\def\\minimize#1{\\displaystyle\\minim_{#1}}\n",
    "\\def\\norm#1{\\|#1\\|}\n",
    "\\def\\Null{{\\mathbf{null}}}\n",
    "\\def\\proj{\\mathbf{proj}}\n",
    "\\def\\R{\\mathbb{R}}\n",
    "\\def\\Re{\\mathbb{R}}\n",
    "\\def\\Rn{\\R^n}\n",
    "\\def\\rank{\\mathbf{rank}}\n",
    "\\def\\range{{\\mathbf{range}}}\n",
    "\\def\\sign{{\\mathbf{sign}}}\n",
    "\\def\\span{{\\mathbf{span}}}\n",
    "\\def\\st{\\hbox{\\rm subject to}}\n",
    "\\def\\T{^\\intercal}\n",
    "\\def\\textt#1{\\quad\\text{#1}\\quad}\n",
    "\\def\\trace{\\mathbf{trace}}\n",
    "\\def\\xbar{\\bar x}\n",
    "$$\n",
    "\n",
    "* **Names:** Ethan Wong\n",
    "* **CWLs:** ethnwng \n",
    "\n",
    "> **Homework submission instructions**\n",
    ">\n",
    "> * Due Friday, Feb 6 at 7 PM.\n",
    "> * Follow Homework Submission Instructions (located in About module) on Canvas.\n",
    "> * If you want TA feedback on your answer to a particular question (beyond your grade on the Emerging/Developing/Proficient scale), clearly indicate this in your answer to the question.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09e29b",
   "metadata": {},
   "source": [
    "## 1 Optimality\n",
    "\n",
    "1.  Beck, Exercise 2.20(v)\n",
    "2.  Beck, Exercise 2.25. (Note: you must argue in both directions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488855f5",
   "metadata": {},
   "source": [
    "Beck 2.20 \n",
    "- v) $f(x_1,x_2,x_3) = x_1^3 + x_2^3 + x_3^3$. Not coercive, choose $|x_1| \\gg |x_2|, |x_3|$ and $x_1 < 0$ then $f\\to-\\infty$ due to odd powers\n",
    "\n",
    "Beck 2.25\n",
    "\n",
    "We want to show for $f(x) = \\mathbf{x^TAx+2b^Tx} + c$ where $\\mathbf{A} \\in \\mathbb{R}^{n \\times m}$ is symmetric, $\\mathbf{b} \\in \\mathbb{R}^n$ and $c \\in\\mathbb{R}$ with $\\mathbf{A} \\succeq 0$  \n",
    "$$\n",
    "f\\text{ bounded below over } \\mathbb{R}^n \\iff b\\in \\range(A) = \\{\\mathbf{Ay} : \\mathbf{y} \\in \\mathbb{R}^n\\}\n",
    "$$\n",
    "\n",
    "1. $f\\text{ bounded below over } \\mathbb{R}^n \\implies b\\in \\range(A) = \\{\\mathbf{Ay} : \\mathbf{y} \\in \\mathbb{R}^n\\}$ \n",
    "\n",
    "Assume for contradiction that $b\\not\\in range(A)$ and let $b$ be decomposed into two components $b = b_r + b_n$ where $b_r \\in range(A)$ and $b_n \\in null(A)$. By assumption, $b\\not\\in range(A) \\implies b_r = 0$. Consider some point $x^*(t) = -t\\cdot b_n$, then\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x^*) &= (-tb_n)^T A (-tb_n) + 2(b_r + b_n)^T(-tb_n) + c \\\\\n",
    "&= t^2 b_n^T\\underbrace{Ab_n}_{=0} - 2t(b_r^Tb_n + b_nb_n) + c \\\\\n",
    "&= 0 - 2t(0 + b_n b_n) + c \\\\\n",
    "&= 0 -2t||b_n||^2 + c\n",
    "\\end{align}\n",
    "$$ \n",
    "now if $t\\to\\infty$, $f\\to-\\infty$ which is a contradiction to $f$ being bounded below on $\\mathbb{R}^n$. Therefore, $b_n =0$ and $b \\in \\range(A)$. \n",
    "\n",
    "2. $b\\in \\range(A) \\implies f \\text{ is bounded below on } \\mathbb{R}^n$\n",
    "\n",
    "Since $b\\in\\range(A)$ there exists $\\mathbf{u}$ such that $A\\mathbf{u} = \\mathbf{b}$. Thus\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x) &= x^T A x + 2(Au)^T x + c \\\\\n",
    "&= x^TAx + 2u^TA^T x + c \\\\\n",
    "&= x^TAx + 2u^TAx + c \\\\\n",
    "&= (x+u)^TA(x+u) - u^TAu + c \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "since $A \\succeq 0$ then $f(x) \\geq 0$. Therefore $f$ is bounded below over $\\mathbb{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6c9eb",
   "metadata": {},
   "source": [
    "## 2 Directional derivative\n",
    "\n",
    "1.  Prove that the directional derivative (when it exists) of a function $f: \\Rn \\to \\R$ is positively homogeneous of degree one; that is, show that for all $\\alpha \\ge 0$:\n",
    "    $$f'(x; \\alpha d) = \\alpha f'(x; d)$$\n",
    "\n",
    "2.  Which unit-norm direction minimizes the directional derivative, i.e., which direction provides the largest instantaneous decrease in $f$ at the point $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061ba28",
   "metadata": {},
   "source": [
    "1. We have that \n",
    "$$\n",
    "\\begin{align}\n",
    "f'(x; ad) = \\lim_{t\\to 0^+} \\frac{f(x+t\\alpha d) - f(x)}{t}\n",
    "\\end{align}\n",
    "$$\n",
    "let $k=\\alpha t$ then $t = \\frac{k}{\\alpha}$ and $t\\to 0^+ \\implies k\\to 0^+$ thus,\n",
    "$$\n",
    "f'(x; \\alpha d) = \\lim_{k\\to 0^+} \\frac{f(x+kd) - f(x)}{k/\\alpha} \\implies f'(x; \\alpha d) = \\alpha \\left[\\lim_{k\\to 0^+} \\frac{f(x+kd) - f(x)}{k}\\right] \\implies f'(x; \\alpha d) = \\alpha f'(x;d)\n",
    "$$\n",
    "\n",
    "2. The gradient of a function always points in the steepest direction at any point $x$. Therefore the directional derivative \n",
    "$$\n",
    "f'(x; d), \\text{ with } d=-\\frac{\\nabla f(x) }{||\\nabla f(x)||}\n",
    "$$\n",
    "provides the largest instantaneous decrease in $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5b5ec",
   "metadata": {},
   "source": [
    "## 3 Nonlinear least squares (source localization)\n",
    "\n",
    "The **source localization problem** can be formulated as the optimization problem:\n",
    "$$\\min_{x \\in \\Rn} \\left\\{ f(x) := \\sum_{i=1}^m (\\|x - c_i\\|^2 - d_i^2)^2 \\right\\}$$\n",
    "where $c_i \\in \\Rn$ are the coordinates of the $i$-th sensor and $d_i \\in \\R$ is the distance from the $i$-th sensor to a source of unknown position. The function $f$ is a **nonlinear least squares** objective. Here we assume that $n=2$ (i.e., the source is in the plane).\n",
    "\n",
    "In this homework, you will analyze the gradient and Jacobian of this function. In the next homework, you will implement a solver for this problem.\n",
    "\n",
    "1.  Compute the gradient of $f(x)$ at an arbitrary point $x \\in \\Rn$.\n",
    "2.  Rewrite the problem as a nonlinear least squares problem in \"standard form\":\n",
    "    $$\\min_{x \\in \\Rn} \\left\\{ g(x) := \\half \\|r(x)\\|^2 \\right\\}$$\n",
    "    where $r(x): \\Rn \\to \\R^m$ is the vector of residual functions. Compute also the Jacobian of $r(x)$, given by:\n",
    "    $$J(x) = \\bmat{ \\nabla r_1(x)\\T \\\\ \\vdots \\\\ \\nabla r_m(x)\\T }$$\n",
    "    which is an $m \\times n$ matrix.\n",
    "3.  Show that as long as the sensor positions $c_1, \\dots, c_m$ are not all colinear (that is, arrayed on a line), the Jacobian $J(x)$ has full rank for all $x \\in \\Rn$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4fa27",
   "metadata": {},
   "source": [
    "1. \n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla f(x) &= \\sum_{i=1}^m \\nabla (||x-c_i||^2 - d_i^2)^2 \\\\\n",
    "& = \\sum_{i=1}^m 2 (||x-c_i||^2 - d_i^2) 2(x-c) \\\\\n",
    "& = 4\\sum_{i=1}^m(||x-c_i||^2 - d_i^2)(x-c)  \n",
    "\\end{align}\n",
    "$$\n",
    "2. Let\n",
    "$$\n",
    "r_i(x) = ||x-c_i||^2 - d_i^2\n",
    "$$\n",
    "then\n",
    "$$\n",
    "J(x) = \\begin{bmatrix} 2(x-c_1)^T \\\\ 2(x-c_2)^T \\\\ \\vdots \\\\ 2(x-c_m)^T \\end{bmatrix}\n",
    "$$\n",
    "3. Assume that the matrix $J$ does not have full rank for $m \\geq 2$. Therefore it must have rank equal to either $1$ or $0$. Thus for each $(x-c_i)$ there exists some direction vector $k$ such that\n",
    "$$\n",
    "x- c_i = a k \\implies c_i = x-ak\n",
    "$$\n",
    "where $a$ is some scalar. The above statement then implies that each $c_i$ are collinear which contradicts the assumption that $c_1, \\dots, c_m$ are not collinear. Therefore $J$ has full rank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d44954",
   "metadata": {},
   "source": [
    "## 4 Positive definiteness\n",
    "\n",
    "Suppose that $A$ is block diagonal, e.g.,\n",
    "\n",
    "$$\n",
    "A = \\bmat{ \n",
    "A^{(1)} & 0      & \\cdots & 0 \\\\ \n",
    "0      & A^{(2)} & \\cdots & 0 \\\\ \n",
    "\\vdots & \\vdots  & \\ddots & \\vdots \\\\ \n",
    "0      & 0      & \\cdots & A^{(l)} \n",
    "}\n",
    "$$\n",
    "\n",
    "Prove that $A \\succeq 0$ if and only if each block $A^{(k)} \\succeq 0$ for all $k$, and $A \\succ 0$ if and only if $A^{(k)} \\succ 0$ for all $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee6e8c-516b-4ab8-8d72-991cb278ad21",
   "metadata": {},
   "source": [
    "Since $A$ is block diagonal the the eigenvalues of $A$ are\n",
    "$$\n",
    "det(A-\\lambda I) = det(A^{(1)} - \\lambda I) \\cdot det(A^{(2)} - \\lambda I) \\cdot \\dots \\cdot det(A^{(l)} - \\lambda I)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\lambda(A) = \\{\\lambda(A^{(1)}) \\cup \\lambda(A^{(2)}) \\cup \\dots \\cup \\lambda(A^{(l)}) \\}\n",
    "$$\n",
    "\n",
    "$\\implies$\n",
    "\n",
    "If $A \\succeq 0$ then $\\lambda(A)$ must all be non-negative, therefore using the fact above that $\\lambda(A)$ is the union of each $\\lambda(A^{(k)})$, each $\\lambda(A^{(k)})$ is also non-negative and $A^{(k)} \\succeq 0$. Similarly, if $A \\succ 0$, then each of its eigenvalues are positive thus $\\lambda(A^{(k)})$ is also positive. Therefore, $A^{(k)} \\succ 0$\n",
    "\n",
    "$\\impliedby$\n",
    "\n",
    "If each $A^{(k)} \\succeq 0$ then using the definition of $\\lambda(A)$ above, every eigenvalue of $A$ is also non-negative. If $A^{(k)} \\succ 0$ then each of their eigenvalues are positive. Once again by definition of $\\lambda(A)$ its eigenvalues are also all positive. Therefore $A \\succ 0$."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "julia"
  },
  "kernelspec": {
   "display_name": "Julia 1.12.4",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
